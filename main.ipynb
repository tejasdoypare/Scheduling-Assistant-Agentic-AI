{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "addbb720",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calender.parser import load_calendar\n",
    "from calender.timezone_utils import to_utc\n",
    "from calender.availability import (\n",
    "    compute_free_slots,\n",
    "    intersect_two_users\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a33fce6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': 'alice',\n",
       " 'timezone': 'Asia/Kolkata',\n",
       " 'working_hours': {'start': '09:00', 'end': '17:00'},\n",
       " 'preferences': {'preferred_hours': ['13:00', '15:00'],\n",
       "  'meeting_flexibility': 0.72},\n",
       " 'events': [{'event_id': 'alice_E0',\n",
       "   'title': 'Meeting',\n",
       "   'start': '2026-01-08T09:00',\n",
       "   'end': '2026-01-08T10:00',\n",
       "   'priority': 'medium',\n",
       "   'movable': True}]}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar = load_calendar(\n",
    "    \"data/scenarios/scenario_001/alice.json\"\n",
    ")\n",
    "\n",
    "calendar\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "21573292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'event_id': 'alice_E0',\n",
       "  'start_utc': datetime.datetime(2026, 1, 8, 3, 30, tzinfo=zoneinfo.ZoneInfo(key='UTC')),\n",
       "  'end_utc': datetime.datetime(2026, 1, 8, 4, 30, tzinfo=zoneinfo.ZoneInfo(key='UTC')),\n",
       "  'priority': 'medium',\n",
       "  'movable': True}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from calender.timezone_utils import to_utc\n",
    "\n",
    "normalized_events = []\n",
    "\n",
    "for event in calendar[\"events\"]:\n",
    "    normalized_events.append({\n",
    "        \"event_id\": event[\"event_id\"],\n",
    "        \"start_utc\": to_utc(event[\"start\"], calendar[\"timezone\"]),\n",
    "        \"end_utc\": to_utc(event[\"end\"], calendar[\"timezone\"]),\n",
    "        \"priority\": event[\"priority\"],\n",
    "        \"movable\": event[\"movable\"]\n",
    "    })\n",
    "\n",
    "normalized_events\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0996029",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.datetime(2026, 1, 8, 3, 30, tzinfo=zoneinfo.ZoneInfo(key='UTC')),\n",
       " datetime.datetime(2026, 1, 8, 11, 30, tzinfo=zoneinfo.ZoneInfo(key='UTC')))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "work_start_local = datetime.fromisoformat(\n",
    "    \"2026-01-08T\" + calendar[\"working_hours\"][\"start\"]\n",
    ").replace(tzinfo=ZoneInfo(calendar[\"timezone\"]))\n",
    "\n",
    "work_end_local = datetime.fromisoformat(\n",
    "    \"2026-01-08T\" + calendar[\"working_hours\"][\"end\"]\n",
    ").replace(tzinfo=ZoneInfo(calendar[\"timezone\"]))\n",
    "\n",
    "work_start_utc = work_start_local.astimezone(ZoneInfo(\"UTC\"))\n",
    "work_end_utc = work_end_local.astimezone(ZoneInfo(\"UTC\"))\n",
    "\n",
    "work_start_utc, work_end_utc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "711794c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start_utc': datetime.datetime(2026, 1, 8, 4, 30, tzinfo=zoneinfo.ZoneInfo(key='UTC')),\n",
       "  'end_utc': datetime.datetime(2026, 1, 8, 11, 30, tzinfo=zoneinfo.ZoneInfo(key='UTC'))}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "free_slots = compute_free_slots(\n",
    "    normalized_events,\n",
    "    work_start_utc,\n",
    "    work_end_utc\n",
    ")\n",
    "\n",
    "free_slots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db62ea5f",
   "metadata": {},
   "source": [
    "### intersect_two_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df4a83b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start_utc': datetime.datetime(2026, 1, 8, 3, 30, tzinfo=zoneinfo.ZoneInfo(key='UTC')),\n",
       "  'end_utc': datetime.datetime(2026, 1, 8, 19, 0, tzinfo=zoneinfo.ZoneInfo(key='UTC'))}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from calender.availability import intersect_two_users\n",
    "\n",
    "\n",
    "calendar_bob = load_calendar(\n",
    "    \"data/scenarios/scenario_001/bob.json\"\n",
    ")\n",
    "calendar_bob\n",
    "\n",
    "\n",
    "from calender.timezone_utils import to_utc\n",
    "\n",
    "normalized_events = []\n",
    "\n",
    "for event in calendar_bob[\"events\"]:\n",
    "    normalized_events.append({\n",
    "        \"event_id\": event[\"event_id\"],\n",
    "        \"start_utc\": to_utc(event[\"start\"], calendar_bob[\"timezone\"]),\n",
    "        \"end_utc\": to_utc(event[\"end\"], calendar_bob[\"timezone\"]),\n",
    "        \"priority\": event[\"priority\"],\n",
    "        \"movable\": event[\"movable\"]\n",
    "    })\n",
    "\n",
    "normalized_events\n",
    "\n",
    "\n",
    "\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n",
    "\n",
    "work_start_local = datetime.fromisoformat(\n",
    "    \"2026-01-08T\" + calendar[\"working_hours\"][\"start\"]\n",
    ").replace(tzinfo=ZoneInfo(calendar[\"timezone\"]))\n",
    "\n",
    "work_end_local = datetime.fromisoformat(\n",
    "    \"2026-01-08T\" + calendar[\"working_hours\"][\"end\"]\n",
    ").replace(tzinfo=ZoneInfo(calendar[\"timezone\"]))\n",
    "\n",
    "work_start_utc = work_start_local.astimezone(ZoneInfo(\"UTC\"))\n",
    "work_end_utc = work_end_local.astimezone(ZoneInfo(\"UTC\"))\n",
    "\n",
    "work_start_utc, work_end_utc\n",
    "\n",
    "free_slots_bobs = compute_free_slots(\n",
    "    normalized_events,\n",
    "    work_start_utc,\n",
    "    work_end_utc\n",
    ")\n",
    "\n",
    "free_slots_bobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77612c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start_utc': datetime.datetime(2026, 1, 8, 4, 30, tzinfo=zoneinfo.ZoneInfo(key='UTC')),\n",
       "  'end_utc': datetime.datetime(2026, 1, 8, 11, 30, tzinfo=zoneinfo.ZoneInfo(key='UTC'))}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intersect_two_users(\n",
    "    free_slots, free_slots_bobs\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65750281",
   "metadata": {},
   "source": [
    "### 11/01/26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "049f2be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from calender.parser import load_calendar\n",
    "from calender.timezone_utils import to_utc\n",
    "from calender.availability import (\n",
    "    compute_free_slots,\n",
    "    intersect_two_users\n",
    ")\n",
    "from calender.constraints import (\n",
    "    tag_constraints,\n",
    "    disruption_score,\n",
    "    timezone_fairness_score,\n",
    "    enrich_slot\n",
    ")\n",
    "\n",
    "from datetime import datetime\n",
    "from zoneinfo import ZoneInfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dd752190",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start_utc': datetime.datetime(2026, 1, 8, 4, 30, tzinfo=zoneinfo.ZoneInfo(key='UTC')),\n",
       "  'end_utc': datetime.datetime(2026, 1, 8, 11, 30, tzinfo=zoneinfo.ZoneInfo(key='UTC'))}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar_alice = load_calendar(\"data/scenarios/scenario_001/alice.json\")\n",
    "\n",
    "# Working hours (Alice)\n",
    "ws_alice = datetime.fromisoformat(\n",
    "    \"2026-01-08T\" + calendar_alice[\"working_hours\"][\"start\"]\n",
    ").replace(tzinfo=ZoneInfo(calendar_alice[\"timezone\"])).astimezone(ZoneInfo(\"UTC\"))\n",
    "\n",
    "we_alice = datetime.fromisoformat(\n",
    "    \"2026-01-08T\" + calendar_alice[\"working_hours\"][\"end\"]\n",
    ").replace(tzinfo=ZoneInfo(calendar_alice[\"timezone\"])).astimezone(ZoneInfo(\"UTC\"))\n",
    "\n",
    "alice_events = [\n",
    "    {\n",
    "        \"start_utc\": to_utc(e[\"start\"], calendar_alice[\"timezone\"]),\n",
    "        \"end_utc\": to_utc(e[\"end\"], calendar_alice[\"timezone\"])\n",
    "    }\n",
    "    for e in calendar_alice[\"events\"]\n",
    "]\n",
    "\n",
    "alice_free_slots = compute_free_slots(alice_events, ws_alice, we_alice)\n",
    "alice_free_slots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "03de2f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'start_utc': datetime.datetime(2026, 1, 8, 17, 0, tzinfo=zoneinfo.ZoneInfo(key='UTC')),\n",
       "  'end_utc': datetime.datetime(2026, 1, 8, 19, 0, tzinfo=zoneinfo.ZoneInfo(key='UTC'))},\n",
       " {'start_utc': datetime.datetime(2026, 1, 8, 20, 0, tzinfo=zoneinfo.ZoneInfo(key='UTC')),\n",
       "  'end_utc': datetime.datetime(2026, 1, 9, 1, 0, tzinfo=zoneinfo.ZoneInfo(key='UTC'))}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calendar_bob = load_calendar(\"data/scenarios/scenario_001/bob.json\")\n",
    "\n",
    "ws_bob = datetime.fromisoformat(\n",
    "    \"2026-01-08T\" + calendar_bob[\"working_hours\"][\"start\"]\n",
    ").replace(tzinfo=ZoneInfo(calendar_bob[\"timezone\"])).astimezone(ZoneInfo(\"UTC\"))\n",
    "\n",
    "we_bob = datetime.fromisoformat(\n",
    "    \"2026-01-08T\" + calendar_bob[\"working_hours\"][\"end\"]\n",
    ").replace(tzinfo=ZoneInfo(calendar_bob[\"timezone\"])).astimezone(ZoneInfo(\"UTC\"))\n",
    "\n",
    "bob_events = [\n",
    "    {\n",
    "        \"start_utc\": to_utc(e[\"start\"], calendar_bob[\"timezone\"]),\n",
    "        \"end_utc\": to_utc(e[\"end\"], calendar_bob[\"timezone\"])\n",
    "    }\n",
    "    for e in calendar_bob[\"events\"]\n",
    "]\n",
    "\n",
    "bob_free_slots = compute_free_slots(bob_events, ws_bob, we_bob)\n",
    "bob_free_slots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23988b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutual_slots = intersect_two_users(\n",
    "    alice_free_slots,\n",
    "    bob_free_slots\n",
    ")\n",
    "\n",
    "mutual_slots\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61bc79d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users_working_hours = {\n",
    "    \"alice\": (ws_alice, we_alice),\n",
    "    \"bob\": (ws_bob, we_bob)\n",
    "}\n",
    "\n",
    "users_flexibility = {\n",
    "    \"alice\": calendar_alice[\"preferences\"][\"meeting_flexibility\"],\n",
    "    \"bob\": calendar_bob[\"preferences\"][\"meeting_flexibility\"]\n",
    "}\n",
    "\n",
    "users_timezones = {\n",
    "    \"alice\": ws_alice.utcoffset().total_seconds() / 3600,\n",
    "    \"bob\": ws_bob.utcoffset().total_seconds() / 3600\n",
    "}\n",
    "\n",
    "enriched_slots = []\n",
    "\n",
    "for i, slot in enumerate(mutual_slots):\n",
    "    constraints = tag_constraints(slot, users_working_hours)\n",
    "    scores = {\n",
    "        \"disruption\": disruption_score(slot, users_flexibility),\n",
    "        \"timezone_fairness\": timezone_fairness_score(slot, users_timezones)\n",
    "    }\n",
    "\n",
    "    enriched_slots.append(\n",
    "        enrich_slot(\n",
    "            slot,\n",
    "            f\"S{i+1}\",\n",
    "            [\"alice\", \"bob\"],\n",
    "            constraints,\n",
    "            scores\n",
    "        )\n",
    "    )\n",
    "\n",
    "enriched_slots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec1f85e1",
   "metadata": {},
   "source": [
    "### 13/01/2026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "951909a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: langchain-google-genai in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (0.8.6)\n",
      "Requirement already satisfied: langchain-core<2.0.0,>=1.2.1 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langchain) (1.2.7)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langchain) (1.0.6)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langchain) (2.12.4)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.6.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (25.0)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langchain-core<2.0.0,>=1.2.1->langchain) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.2.1->langchain) (3.0.0)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.6)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
      "Requirement already satisfied: httpx>=0.25.2 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.10.1 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (0.24.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph<1.1.0,>=1.0.2->langchain) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langchain-google-genai) (1.58.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.47.0)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (15.0.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core<2.0.0,>=1.2.1->langchain) (2.6.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.6.1)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-generativeai) (2.29.0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-generativeai) (2.188.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-generativeai) (5.29.5)\n",
      "Requirement already satisfied: tqdm in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.27.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-api-core->google-generativeai) (1.72.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.76.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.31.1)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.3.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
      "Requirement already satisfied: pyparsing<4,>=3.0.4 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain langchain-google-genai google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "54fb4ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCWrm16Z_mhoYldya-QrrdnH8yipOpiER4\"\n",
    "\n",
    "# Google AI Studio API key is now set in environment variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eaec951f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-core in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: langchain in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (1.2.4)\n",
      "Requirement already satisfied: langchain-google-genai in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (4.2.0)\n",
      "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langchain-core) (1.33)\n",
      "Requirement already satisfied: langsmith<1.0.0,>=0.3.45 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langchain-core) (0.6.2)\n",
      "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langchain-core) (25.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langchain-core) (2.12.4)\n",
      "Requirement already satisfied: pyyaml<7.0.0,>=5.3.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langchain-core) (6.0.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langchain-core) (9.1.2)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langchain-core) (4.15.0)\n",
      "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langchain-core) (0.13.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (3.11.5)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.0)\n",
      "Requirement already satisfied: requests>=2.0.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (2.32.5)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langsmith<1.0.0,>=0.3.45->langchain-core) (0.24.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (4.12.1)\n",
      "Requirement already satisfied: certifi in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (1.0.9)\n",
      "Requirement already satisfied: idna in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<1.0.0,>=0.3.45->langchain-core) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.41.5 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (2.41.5)\n",
      "Requirement already satisfied: typing-inspection>=0.4.2 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core) (0.4.2)\n",
      "Requirement already satisfied: langgraph<1.1.0,>=1.0.2 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langchain) (1.0.6)\n",
      "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (4.0.0)\n",
      "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (1.0.6)\n",
      "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (0.3.3)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langgraph<1.1.0,>=1.0.2->langchain) (3.6.0)\n",
      "Requirement already satisfied: ormsgpack>=1.12.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph<1.1.0,>=1.0.2->langchain) (1.12.1)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langchain-google-genai) (1.2.0)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.56.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from langchain-google-genai) (1.58.0)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.47.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (2.47.0)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (15.0.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.9.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-genai<2.0.0,>=1.56.0->langchain-google-genai) (1.3.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (4.9.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from requests>=2.0.0->langsmith<1.0.0,>=0.3.45->langchain-core) (2.6.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\lenovo\\miniconda3\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth<3.0.0,>=2.47.0->google-auth[requests]<3.0.0,>=2.47.0->google-genai<2.0.0,>=1.56.0->langchain-google-genai) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -U langchain-core langchain langchain-google-genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41ea1230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduler agent imported successfully\n"
     ]
    }
   ],
   "source": [
    "from agents.scheduler_agent import run_scheduler_agent\n",
    "print(\"Scheduler agent imported successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1040b139",
   "metadata": {},
   "outputs": [
    {
     "ename": "ChatGoogleGenerativeAIError",
     "evalue": "Error calling model 'gemini-1.5-flash' (NOT_FOUND): 404 NOT_FOUND. {'error': {'code': 404, 'message': 'models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mClientError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:3047\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   3046\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3047\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3048\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3049\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3050\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\google\\genai\\models.py:5215\u001b[39m, in \u001b[36mModels.generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   5214\u001b[39m i += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m5215\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5216\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparsed_config\u001b[49m\n\u001b[32m   5217\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5219\u001b[39m function_map = _extra_utils.get_function_map(parsed_config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\google\\genai\\models.py:3997\u001b[39m, in \u001b[36mModels._generate_content\u001b[39m\u001b[34m(self, model, contents, config)\u001b[39m\n\u001b[32m   3995\u001b[39m request_dict = _common.encode_unserializable_types(request_dict)\n\u001b[32m-> \u001b[39m\u001b[32m3997\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_api_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3998\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\n\u001b[32m   3999\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4001\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\n\u001b[32m   4002\u001b[39m     config, \u001b[33m'\u001b[39m\u001b[33mshould_return_http_response\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   4003\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\google\\genai\\_api_client.py:1379\u001b[39m, in \u001b[36mBaseApiClient.request\u001b[39m\u001b[34m(self, http_method, path, request_dict, http_options)\u001b[39m\n\u001b[32m   1376\u001b[39m http_request = \u001b[38;5;28mself\u001b[39m._build_request(\n\u001b[32m   1377\u001b[39m     http_method, path, request_dict, http_options\n\u001b[32m   1378\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1379\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_options\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m   1380\u001b[39m response_body = (\n\u001b[32m   1381\u001b[39m     response.response_stream[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m response.response_stream \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1382\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\google\\genai\\_api_client.py:1213\u001b[39m, in \u001b[36mBaseApiClient._request\u001b[39m\u001b[34m(self, http_request, http_options, stream)\u001b[39m\n\u001b[32m   1212\u001b[39m     retry = tenacity.Retrying(**retry_kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m1213\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_once\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhttp_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[no-any-return]\u001b[39;00m\n\u001b[32m   1215\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retry(\u001b[38;5;28mself\u001b[39m._request_once, http_request, stream)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\tenacity\\__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\tenacity\\__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\tenacity\\__init__.py:400\u001b[39m, in \u001b[36mBaseRetrying._post_retry_check_actions.<locals>.<lambda>\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m.iter_state.is_explicit_retry \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.retry_run_result):\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     \u001b[38;5;28mself\u001b[39m._add_action_func(\u001b[38;5;28;01mlambda\u001b[39;00m rs: \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43moutcome\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    401\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\miniconda3\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\miniconda3\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\tenacity\\__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    479\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\google\\genai\\_api_client.py:1192\u001b[39m, in \u001b[36mBaseApiClient._request_once\u001b[39m\u001b[34m(self, http_request, stream)\u001b[39m\n\u001b[32m   1185\u001b[39m response = \u001b[38;5;28mself\u001b[39m._httpx_client.request(\n\u001b[32m   1186\u001b[39m     method=http_request.method,\n\u001b[32m   1187\u001b[39m     url=http_request.url,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1190\u001b[39m     timeout=http_request.timeout,\n\u001b[32m   1191\u001b[39m )\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m \u001b[43merrors\u001b[49m\u001b[43m.\u001b[49m\u001b[43mAPIError\u001b[49m\u001b[43m.\u001b[49m\u001b[43mraise_for_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1193\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m HttpResponse(\n\u001b[32m   1194\u001b[39m     response.headers, response \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m [response.text]\n\u001b[32m   1195\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\google\\genai\\errors.py:121\u001b[39m, in \u001b[36mAPIError.raise_for_response\u001b[39m\u001b[34m(cls, response)\u001b[39m\n\u001b[32m    119\u001b[39m   response_json = response.body_segments[\u001b[32m0\u001b[39m].get(\u001b[33m'\u001b[39m\u001b[33merror\u001b[39m\u001b[33m'\u001b[39m, {})\n\u001b[32m--> \u001b[39m\u001b[32m121\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mraise_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus_code\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_json\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\google\\genai\\errors.py:146\u001b[39m, in \u001b[36mAPIError.raise_error\u001b[39m\u001b[34m(cls, status_code, response_json, response)\u001b[39m\n\u001b[32m    145\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[32m400\u001b[39m <= status_code < \u001b[32m500\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ClientError(status_code, response_json, response)\n\u001b[32m    147\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[32m500\u001b[39m <= status_code < \u001b[32m600\u001b[39m:\n",
      "\u001b[31mClientError\u001b[39m: 404 NOT_FOUND. {'error': {'code': 404, 'message': 'models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01magents\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mscheduler_agent\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_scheduler_agent\n\u001b[32m      2\u001b[39m scheduler_input = {\n\u001b[32m      3\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mmeeting_request\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m      4\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtitle\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mProject Discussion\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      7\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mcandidate_slots\u001b[39m\u001b[33m\"\u001b[39m: []\n\u001b[32m      8\u001b[39m }\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m decision =\u001b[43mrun_scheduler_agent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscheduler_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mprompts/scheduler.txt\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m decision\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Hackathon\\Scheduling Assistant\\agents\\scheduler_agent.py:14\u001b[39m, in \u001b[36mrun_scheduler_agent\u001b[39m\u001b[34m(input_payload, prompt_text)\u001b[39m\n\u001b[32m      7\u001b[39m llm = ChatGoogleGenerativeAI(model=\u001b[33m\"\u001b[39m\u001b[33mgemini-1.5-flash\u001b[39m\u001b[33m\"\u001b[39m, temperature=\u001b[32m0\u001b[39m)\n\u001b[32m      9\u001b[39m prompt = PromptTemplate(\n\u001b[32m     10\u001b[39m     template=prompt_text + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mINPUT:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{input}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mOUTPUT:\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     11\u001b[39m     input_variables=[\u001b[33m\"\u001b[39m\u001b[33minput\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     12\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m response = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_payload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Extract content from the response\u001b[39;00m\n\u001b[32m     19\u001b[39m response_content = response.content \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(response, \u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:2535\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   2532\u001b[39m         msg = \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.code_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   2533\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m-> \u001b[39m\u001b[32m2535\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:402\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    388\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    390\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    395\u001b[39m     **kwargs: Any,\n\u001b[32m    396\u001b[39m ) -> AIMessage:\n\u001b[32m    397\u001b[39m     config = ensure_config(config)\n\u001b[32m    398\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    399\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAIMessage\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    400\u001b[39m         cast(\n\u001b[32m    401\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m402\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    403\u001b[39m \u001b[43m                \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    404\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    405\u001b[39m \u001b[43m                \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    406\u001b[39m \u001b[43m                \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    407\u001b[39m \u001b[43m                \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    408\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    409\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    410\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    411\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    412\u001b[39m         ).message,\n\u001b[32m    413\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1121\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m   1112\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m   1113\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m   1114\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1118\u001b[39m     **kwargs: Any,\n\u001b[32m   1119\u001b[39m ) -> LLMResult:\n\u001b[32m   1120\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m-> \u001b[39m\u001b[32m1121\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:931\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(input_messages):\n\u001b[32m    929\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    930\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m931\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    937\u001b[39m         )\n\u001b[32m    938\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    939\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1233\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1231\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1232\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1233\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1234\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1235\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1236\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1237\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:3051\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   3047\u001b[39m     response: GenerateContentResponse = \u001b[38;5;28mself\u001b[39m.client.models.generate_content(\n\u001b[32m   3048\u001b[39m         **request,\n\u001b[32m   3049\u001b[39m     )\n\u001b[32m   3050\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClientError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m-> \u001b[39m\u001b[32m3051\u001b[39m     \u001b[43m_handle_client_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3053\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:145\u001b[39m, in \u001b[36m_handle_client_error\u001b[39m\u001b[34m(e, request)\u001b[39m\n\u001b[32m    143\u001b[39m model_name = request.get(\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33munknown\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    144\u001b[39m msg = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError calling model \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00me.status\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m): \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[31mChatGoogleGenerativeAIError\u001b[39m: Error calling model 'gemini-1.5-flash' (NOT_FOUND): 404 NOT_FOUND. {'error': {'code': 404, 'message': 'models/gemini-1.5-flash is not found for API version v1beta, or is not supported for generateContent. Call ListModels to see the list of available models and their supported methods.', 'status': 'NOT_FOUND'}}"
     ]
    }
   ],
   "source": [
    "from agents.scheduler_agent import run_scheduler_agent\n",
    "scheduler_input = {\n",
    "    \"meeting_request\": {\n",
    "        \"title\": \"Project Discussion\",\n",
    "        \"duration_minutes\": 60\n",
    "    },\n",
    "    \"candidate_slots\": []\n",
    "}\n",
    "\n",
    "decision =run_scheduler_agent(\n",
    "    scheduler_input,\n",
    "    open(\"prompts/scheduler.txt\").read()\n",
    ")\n",
    "\n",
    "decision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50fa7ec3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scheduler agent reloaded with updated model\n"
     ]
    }
   ],
   "source": [
    "# Reload the module to get the updated model name\n",
    "import importlib\n",
    "import sys\n",
    "if 'agents.scheduler_agent' in sys.modules:\n",
    "    importlib.reload(sys.modules['agents.scheduler_agent'])\n",
    "\n",
    "from agents.scheduler_agent import run_scheduler_agent\n",
    "print(\"Scheduler agent reloaded with updated model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f3f5f6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_13504\\697110119.py:2: FutureWarning: \n",
      "\n",
      "All support for the `google.generativeai` package has ended. It will no longer be receiving \n",
      "updates or bug fixes. Please switch to the `google.genai` package as soon as possible.\n",
      "See README for more details:\n",
      "\n",
      "https://github.com/google-gemini/deprecated-generative-ai-python/blob/main/README.md\n",
      "\n",
      "  import google.generativeai as genai\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models:\n",
      "  models/gemini-2.5-flash\n",
      "    Display Name: Gemini 2.5 Flash\n",
      "    Description: Stable version of Gemini 2.5 Flash, our mid-size multimodal model that supports up to 1 million tokens, released in June of 2025.\n",
      "\n",
      "  models/gemini-2.5-pro\n",
      "    Display Name: Gemini 2.5 Pro\n",
      "    Description: Stable release (June 17th, 2025) of Gemini 2.5 Pro\n",
      "\n",
      "  models/gemini-2.0-flash-exp\n",
      "    Display Name: Gemini 2.0 Flash Experimental\n",
      "    Description: Gemini 2.0 Flash Experimental\n",
      "\n",
      "  models/gemini-2.0-flash\n",
      "    Display Name: Gemini 2.0 Flash\n",
      "    Description: Gemini 2.0 Flash\n",
      "\n",
      "  models/gemini-2.0-flash-001\n",
      "    Display Name: Gemini 2.0 Flash 001\n",
      "    Description: Stable version of Gemini 2.0 Flash, our fast and versatile multimodal model for scaling across diverse tasks, released in January of 2025.\n",
      "\n",
      "  models/gemini-2.0-flash-exp-image-generation\n",
      "    Display Name: Gemini 2.0 Flash (Image Generation) Experimental\n",
      "    Description: Gemini 2.0 Flash (Image Generation) Experimental\n",
      "\n",
      "  models/gemini-2.0-flash-lite-001\n",
      "    Display Name: Gemini 2.0 Flash-Lite 001\n",
      "    Description: Stable version of Gemini 2.0 Flash-Lite\n",
      "\n",
      "  models/gemini-2.0-flash-lite\n",
      "    Display Name: Gemini 2.0 Flash-Lite\n",
      "    Description: Gemini 2.0 Flash-Lite\n",
      "\n",
      "  models/gemini-2.0-flash-lite-preview-02-05\n",
      "    Display Name: Gemini 2.0 Flash-Lite Preview 02-05\n",
      "    Description: Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite\n",
      "\n",
      "  models/gemini-2.0-flash-lite-preview\n",
      "    Display Name: Gemini 2.0 Flash-Lite Preview\n",
      "    Description: Preview release (February 5th, 2025) of Gemini 2.0 Flash-Lite\n",
      "\n",
      "  models/gemini-exp-1206\n",
      "    Display Name: Gemini Experimental 1206\n",
      "    Description: Experimental release (March 25th, 2025) of Gemini 2.5 Pro\n",
      "\n",
      "  models/gemini-2.5-flash-preview-tts\n",
      "    Display Name: Gemini 2.5 Flash Preview TTS\n",
      "    Description: Gemini 2.5 Flash Preview TTS\n",
      "\n",
      "  models/gemini-2.5-pro-preview-tts\n",
      "    Display Name: Gemini 2.5 Pro Preview TTS\n",
      "    Description: Gemini 2.5 Pro Preview TTS\n",
      "\n",
      "  models/gemma-3-1b-it\n",
      "    Display Name: Gemma 3 1B\n",
      "    Description: \n",
      "\n",
      "  models/gemma-3-4b-it\n",
      "    Display Name: Gemma 3 4B\n",
      "    Description: \n",
      "\n",
      "  models/gemma-3-12b-it\n",
      "    Display Name: Gemma 3 12B\n",
      "    Description: \n",
      "\n",
      "  models/gemma-3-27b-it\n",
      "    Display Name: Gemma 3 27B\n",
      "    Description: \n",
      "\n",
      "  models/gemma-3n-e4b-it\n",
      "    Display Name: Gemma 3n E4B\n",
      "    Description: \n",
      "\n",
      "  models/gemma-3n-e2b-it\n",
      "    Display Name: Gemma 3n E2B\n",
      "    Description: \n",
      "\n",
      "  models/gemini-flash-latest\n",
      "    Display Name: Gemini Flash Latest\n",
      "    Description: Latest release of Gemini Flash\n",
      "\n",
      "  models/gemini-flash-lite-latest\n",
      "    Display Name: Gemini Flash-Lite Latest\n",
      "    Description: Latest release of Gemini Flash-Lite\n",
      "\n",
      "  models/gemini-pro-latest\n",
      "    Display Name: Gemini Pro Latest\n",
      "    Description: Latest release of Gemini Pro\n",
      "\n",
      "  models/gemini-2.5-flash-lite\n",
      "    Display Name: Gemini 2.5 Flash-Lite\n",
      "    Description: Stable version of Gemini 2.5 Flash-Lite, released in July of 2025\n",
      "\n",
      "  models/gemini-2.5-flash-image-preview\n",
      "    Display Name: Nano Banana\n",
      "    Description: Gemini 2.5 Flash Preview Image\n",
      "\n",
      "  models/gemini-2.5-flash-image\n",
      "    Display Name: Nano Banana\n",
      "    Description: Gemini 2.5 Flash Preview Image\n",
      "\n",
      "  models/gemini-2.5-flash-preview-09-2025\n",
      "    Display Name: Gemini 2.5 Flash Preview Sep 2025\n",
      "    Description: Gemini 2.5 Flash Preview Sep 2025\n",
      "\n",
      "  models/gemini-2.5-flash-lite-preview-09-2025\n",
      "    Display Name: Gemini 2.5 Flash-Lite Preview Sep 2025\n",
      "    Description: Preview release (Septempber 25th, 2025) of Gemini 2.5 Flash-Lite\n",
      "\n",
      "  models/gemini-3-pro-preview\n",
      "    Display Name: Gemini 3 Pro Preview\n",
      "    Description: Gemini 3 Pro Preview\n",
      "\n",
      "  models/gemini-3-flash-preview\n",
      "    Display Name: Gemini 3 Flash Preview\n",
      "    Description: Gemini 3 Flash Preview\n",
      "\n",
      "  models/gemini-3-pro-image-preview\n",
      "    Display Name: Nano Banana Pro\n",
      "    Description: Gemini 3 Pro Image Preview\n",
      "\n",
      "  models/nano-banana-pro-preview\n",
      "    Display Name: Nano Banana Pro\n",
      "    Description: Gemini 3 Pro Image Preview\n",
      "\n",
      "  models/gemini-robotics-er-1.5-preview\n",
      "    Display Name: Gemini Robotics-ER 1.5 Preview\n",
      "    Description: Gemini Robotics-ER 1.5 Preview\n",
      "\n",
      "  models/gemini-2.5-computer-use-preview-10-2025\n",
      "    Display Name: Gemini 2.5 Computer Use Preview 10-2025\n",
      "    Description: Gemini 2.5 Computer Use Preview 10-2025\n",
      "\n",
      "  models/deep-research-pro-preview-12-2025\n",
      "    Display Name: Deep Research Pro Preview (Dec-12-2025)\n",
      "    Description: Preview release (December 12th, 2025) of Deep Research Pro\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's check what models are available\n",
    "import google.generativeai as genai\n",
    "import os\n",
    "\n",
    "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "print(\"Available models:\")\n",
    "for model in genai.list_models():\n",
    "    if 'generateContent' in model.supported_generation_methods:\n",
    "        print(f\"  {model.name}\")\n",
    "        print(f\"    Display Name: {model.display_name}\")\n",
    "        print(f\"    Description: {model.description}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53378567",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models:\n",
      "  models/embedding-gecko-001\n",
      "    Display Name: Embedding Gecko\n",
      "\n",
      "  models/gemini-2.5-flash\n",
      "    Display Name: Gemini 2.5 Flash\n",
      "\n",
      "  models/gemini-2.5-pro\n",
      "    Display Name: Gemini 2.5 Pro\n",
      "\n",
      "  models/gemini-2.0-flash-exp\n",
      "    Display Name: Gemini 2.0 Flash Experimental\n",
      "\n",
      "  models/gemini-2.0-flash\n",
      "    Display Name: Gemini 2.0 Flash\n",
      "\n",
      "  models/gemini-2.0-flash-001\n",
      "    Display Name: Gemini 2.0 Flash 001\n",
      "\n",
      "  models/gemini-2.0-flash-exp-image-generation\n",
      "    Display Name: Gemini 2.0 Flash (Image Generation) Experimental\n",
      "\n",
      "  models/gemini-2.0-flash-lite-001\n",
      "    Display Name: Gemini 2.0 Flash-Lite 001\n",
      "\n",
      "  models/gemini-2.0-flash-lite\n",
      "    Display Name: Gemini 2.0 Flash-Lite\n",
      "\n",
      "  models/gemini-2.0-flash-lite-preview-02-05\n",
      "    Display Name: Gemini 2.0 Flash-Lite Preview 02-05\n",
      "\n",
      "  models/gemini-2.0-flash-lite-preview\n",
      "    Display Name: Gemini 2.0 Flash-Lite Preview\n",
      "\n",
      "  models/gemini-exp-1206\n",
      "    Display Name: Gemini Experimental 1206\n",
      "\n",
      "  models/gemini-2.5-flash-preview-tts\n",
      "    Display Name: Gemini 2.5 Flash Preview TTS\n",
      "\n",
      "  models/gemini-2.5-pro-preview-tts\n",
      "    Display Name: Gemini 2.5 Pro Preview TTS\n",
      "\n",
      "  models/gemma-3-1b-it\n",
      "    Display Name: Gemma 3 1B\n",
      "\n",
      "  models/gemma-3-4b-it\n",
      "    Display Name: Gemma 3 4B\n",
      "\n",
      "  models/gemma-3-12b-it\n",
      "    Display Name: Gemma 3 12B\n",
      "\n",
      "  models/gemma-3-27b-it\n",
      "    Display Name: Gemma 3 27B\n",
      "\n",
      "  models/gemma-3n-e4b-it\n",
      "    Display Name: Gemma 3n E4B\n",
      "\n",
      "  models/gemma-3n-e2b-it\n",
      "    Display Name: Gemma 3n E2B\n",
      "\n",
      "  models/gemini-flash-latest\n",
      "    Display Name: Gemini Flash Latest\n",
      "\n",
      "  models/gemini-flash-lite-latest\n",
      "    Display Name: Gemini Flash-Lite Latest\n",
      "\n",
      "  models/gemini-pro-latest\n",
      "    Display Name: Gemini Pro Latest\n",
      "\n",
      "  models/gemini-2.5-flash-lite\n",
      "    Display Name: Gemini 2.5 Flash-Lite\n",
      "\n",
      "  models/gemini-2.5-flash-image-preview\n",
      "    Display Name: Nano Banana\n",
      "\n",
      "  models/gemini-2.5-flash-image\n",
      "    Display Name: Nano Banana\n",
      "\n",
      "  models/gemini-2.5-flash-preview-09-2025\n",
      "    Display Name: Gemini 2.5 Flash Preview Sep 2025\n",
      "\n",
      "  models/gemini-2.5-flash-lite-preview-09-2025\n",
      "    Display Name: Gemini 2.5 Flash-Lite Preview Sep 2025\n",
      "\n",
      "  models/gemini-3-pro-preview\n",
      "    Display Name: Gemini 3 Pro Preview\n",
      "\n",
      "  models/gemini-3-flash-preview\n",
      "    Display Name: Gemini 3 Flash Preview\n",
      "\n",
      "  models/gemini-3-pro-image-preview\n",
      "    Display Name: Nano Banana Pro\n",
      "\n",
      "  models/nano-banana-pro-preview\n",
      "    Display Name: Nano Banana Pro\n",
      "\n",
      "  models/gemini-robotics-er-1.5-preview\n",
      "    Display Name: Gemini Robotics-ER 1.5 Preview\n",
      "\n",
      "  models/gemini-2.5-computer-use-preview-10-2025\n",
      "    Display Name: Gemini 2.5 Computer Use Preview 10-2025\n",
      "\n",
      "  models/deep-research-pro-preview-12-2025\n",
      "    Display Name: Deep Research Pro Preview (Dec-12-2025)\n",
      "\n",
      "  models/embedding-001\n",
      "    Display Name: Embedding 001\n",
      "\n",
      "  models/text-embedding-004\n",
      "    Display Name: Text Embedding 004\n",
      "\n",
      "  models/gemini-embedding-exp-03-07\n",
      "    Display Name: Gemini Embedding Experimental 03-07\n",
      "\n",
      "  models/gemini-embedding-exp\n",
      "    Display Name: Gemini Embedding Experimental\n",
      "\n",
      "  models/gemini-embedding-001\n",
      "    Display Name: Gemini Embedding 001\n",
      "\n",
      "  models/aqa\n",
      "    Display Name: Model that performs Attributed Question Answering.\n",
      "\n",
      "  models/imagen-4.0-generate-preview-06-06\n",
      "    Display Name: Imagen 4 (Preview)\n",
      "\n",
      "  models/imagen-4.0-ultra-generate-preview-06-06\n",
      "    Display Name: Imagen 4 Ultra (Preview)\n",
      "\n",
      "  models/imagen-4.0-generate-001\n",
      "    Display Name: Imagen 4\n",
      "\n",
      "  models/imagen-4.0-ultra-generate-001\n",
      "    Display Name: Imagen 4 Ultra\n",
      "\n",
      "  models/imagen-4.0-fast-generate-001\n",
      "    Display Name: Imagen 4 Fast\n",
      "\n",
      "  models/veo-2.0-generate-001\n",
      "    Display Name: Veo 2\n",
      "\n",
      "  models/veo-3.0-generate-001\n",
      "    Display Name: Veo 3\n",
      "\n",
      "  models/veo-3.0-fast-generate-001\n",
      "    Display Name: Veo 3 fast\n",
      "\n",
      "  models/veo-3.1-generate-preview\n",
      "    Display Name: Veo 3.1\n",
      "\n",
      "  models/veo-3.1-fast-generate-preview\n",
      "    Display Name: Veo 3.1 fast\n",
      "\n",
      "  models/gemini-2.5-flash-native-audio-latest\n",
      "    Display Name: Gemini 2.5 Flash Native Audio Latest\n",
      "\n",
      "  models/gemini-2.5-flash-native-audio-preview-09-2025\n",
      "    Display Name: Gemini 2.5 Flash Native Audio Preview 09-2025\n",
      "\n",
      "  models/gemini-2.5-flash-native-audio-preview-12-2025\n",
      "    Display Name: Gemini 2.5 Flash Native Audio Preview 12-2025\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try with google.genai package\n",
    "import google.genai as genai\n",
    "import os\n",
    "\n",
    "client = genai.Client(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "try:\n",
    "    models = client.models.list()\n",
    "    print(\"Available models:\")\n",
    "    for model in models:\n",
    "        print(f\"  {model.name}\")\n",
    "        print(f\"    Display Name: {model.display_name}\")\n",
    "        if hasattr(model, 'supported_generation_methods'):\n",
    "            print(f\"    Supported Methods: {model.supported_generation_methods}\")\n",
    "        print()\n",
    "except Exception as e:\n",
    "    print(f\"Error listing models: {e}\")\n",
    "    \n",
    "    # Try some common model names\n",
    "    common_models = [\n",
    "        \"gemini-2.0-flash-exp\",\n",
    "        \"gemini-1.5-pro\",\n",
    "        \"gemini-1.5-flash\",\n",
    "        \"gemini-pro-latest\",\n",
    "        \"gemini-pro\"\n",
    "    ]\n",
    "    \n",
    "    print(\"\\nTrying common model names:\")\n",
    "    for model_name in common_models:\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=model_name,\n",
    "                contents=\"Say hello\",\n",
    "                config={\"max_output_tokens\": 10}\n",
    "            )\n",
    "            print(f\" {model_name} works\")\n",
    "            break\n",
    "        except Exception as model_error:\n",
    "            print(f\" {model_name}: {model_error}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b1e756",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Scheduler agent working!\n",
      "Response: {'response': '```json\\n{\\n  \"decision\": \"negotiate_or_reschedule\",\\n  \"selected_slot_id\": null,\\n  \"reasoning\": \"No candidate slots were provided, requiring negotiation or rescheduling.\",\\n  \"confidence\": 1.0\\n}\\n```', 'error': 'Failed to parse JSON response'}\n"
     ]
    }
   ],
   "source": [
    "# Reload the module again with the correct model name\n",
    "import importlib\n",
    "import sys\n",
    "if 'agents.scheduler_agent' in sys.modules:\n",
    "    importlib.reload(sys.modules['agents.scheduler_agent'])\n",
    "\n",
    "from agents.scheduler_agent import run_scheduler_agent\n",
    "\n",
    "# Test the scheduler agent with a simple request\n",
    "scheduler_input = {\n",
    "    \"meeting_request\": {\n",
    "        \"title\": \"Project Discussion\",\n",
    "        \"duration_minutes\": 60\n",
    "    },\n",
    "    \"candidate_slots\": []\n",
    "}\n",
    "\n",
    "try:\n",
    "    decision = run_scheduler_agent(\n",
    "        scheduler_input,\n",
    "        open(\"prompts/scheduler.txt\").read()\n",
    "    )\n",
    "    print(\" Scheduler agent working!\")\n",
    "    print(\"Response:\", decision)\n",
    "except Exception as e:\n",
    "    print(f\" Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bce7c4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final decision: {'decision': 'negotiate_or_reschedule', 'selected_slot_id': None, 'reasoning': 'No candidate slots were provided, requiring negotiation or rescheduling.', 'confidence': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Test the improved JSON parsing\n",
    "import importlib\n",
    "import sys\n",
    "if 'agents.scheduler_agent' in sys.modules:\n",
    "    importlib.reload(sys.modules['agents.scheduler_agent'])\n",
    "\n",
    "from agents.scheduler_agent import run_scheduler_agent\n",
    "\n",
    "scheduler_input = {\n",
    "    \"meeting_request\": {\n",
    "        \"title\": \"Project Discussion\", \n",
    "        \"duration_minutes\": 60\n",
    "    },\n",
    "    \"candidate_slots\": []\n",
    "}\n",
    "\n",
    "decision = run_scheduler_agent(\n",
    "    scheduler_input,\n",
    "    open(\"prompts/scheduler.txt\").read()\n",
    ")\n",
    "\n",
    "print(\"Final decision:\", decision)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4155d8",
   "metadata": {},
   "source": [
    "# PHASE 5: Multi-Agent Negotiation\n",
    "\n",
    "**Goal:** Show agentic behavior through participant agents that can negotiate with the scheduler\n",
    "\n",
    "**Key Features:**\n",
    "- Multiple participant agents with different personalities and flexibility scores\n",
    "- Iterative negotiation rounds (proposal  response  adaptation)\n",
    "- Realistic agent behaviors (accept/counter/decline based on constraints)\n",
    "- Negotiation orchestration with conversation history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308d4efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " PARTICIPANT PROFILES\n",
      "========================================\n",
      "\n",
      " Alice\n",
      "   Flexibility: 0.8\n",
      "   Personality: accommodating\n",
      "   Working Hours: {'start': '09:00', 'end': '17:00'}\n",
      "   Timezone: Asia/Kolkata\n",
      "   Priorities: client_meetings, project_deadlines\n",
      "\n",
      " Bob\n",
      "   Flexibility: 0.4\n",
      "   Personality: structured\n",
      "   Working Hours: {'start': '08:00', 'end': '16:00'}\n",
      "   Timezone: US/Pacific\n",
      "   Priorities: deep_work, no_late_meetings\n",
      "\n",
      " Charlie\n",
      "   Flexibility: 0.9\n",
      "   Personality: flexible\n",
      "   Working Hours: {'start': '10:00', 'end': '18:00'}\n",
      "   Timezone: Europe/London\n",
      "   Priorities: collaboration, team_alignment\n",
      "\n",
      " Created 3 participant agents ready for negotiation!\n"
     ]
    }
   ],
   "source": [
    "# Import and test the participant agent\n",
    "from agents.participant_agent import ParticipantAgent, create_participant_profiles\n",
    "import os\n",
    "\n",
    "# Create participant profiles\n",
    "profiles = create_participant_profiles()\n",
    "\n",
    "print(\"PARTICIPANT PROFILES\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "for name, profile in profiles.items():\n",
    "    print(f\"\\n{name}\")\n",
    "    print(f\"   Flexibility: {profile['flexibility_score']}\")\n",
    "    print(f\"   Personality: {profile['personality']}\")\n",
    "    print(f\"   Working Hours: {profile['working_hours']}\")\n",
    "    print(f\"   Timezone: {profile['timezone']}\")\n",
    "    print(f\"   Priorities: {', '.join(profile['priorities'])}\")\n",
    "\n",
    "print(f\"\\nCreated {len(profiles)} participant agents ready for negotiation!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151c2d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " TESTING INDIVIDUAL PARTICIPANT RESPONSE\n",
      "==================================================\n",
      "Meeting: Product Strategy Review\n",
      "Proposed time: 2026-01-16T22:00:00Z (Late night for Alice in India)\n",
      "\n",
      " Alice's response:\n",
      "   Decision: counter_propose\n",
      "   Reasoning: The proposed time slot (03:30 AM - 05:00 AM IST) falls significantly outside my standard working hours (09:00 - 17:00 IST) and is during typical sleeping hours. While the meeting is high priority, this time is not feasible for me to attend effectively.\n",
      "   Flexibility: 0.8\n",
      "   Alternatives: 2 suggested\n",
      "\n",
      " Single participant test completed!\n"
     ]
    }
   ],
   "source": [
    "# Test single participant response\n",
    "import os\n",
    "\n",
    "# Create Alice participant\n",
    "alice = ParticipantAgent(\"Alice\", profiles[\"Alice\"], os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "# Test meeting proposal\n",
    "meeting_request = {\n",
    "    \"title\": \"Product Strategy Review\",\n",
    "    \"duration_minutes\": 90,\n",
    "    \"priority\": \"high\"\n",
    "}\n",
    "\n",
    "# Proposal that conflicts with Alice's timezone (late night in India)\n",
    "proposed_slot = {\n",
    "    \"start_utc\": \"2026-01-16T22:00:00Z\",  # 3:30 AM in India \n",
    "    \"end_utc\": \"2026-01-16T23:30:00Z\",\n",
    "    \"participants\": [\"Alice\", \"Bob\", \"Charlie\"]\n",
    "}\n",
    "\n",
    "print(\"TESTING INDIVIDUAL PARTICIPANT RESPONSE\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Meeting: {meeting_request['title']}\")\n",
    "print(f\"Proposed time: {proposed_slot['start_utc']} (Late night for Alice in India)\")\n",
    "print(f\"\\nAlice's response:\")\n",
    "\n",
    "try:\n",
    "    alice_response = alice.respond_to_proposal(meeting_request, proposed_slot)\n",
    "    print(f\"   Decision: {alice_response.get('decision')}\")\n",
    "    print(f\"   Reasoning: {alice_response.get('reasoning')}\")\n",
    "    print(f\"   Flexibility: {alice_response.get('flexibility')}\")\n",
    "    \n",
    "    if alice_response.get('alternative_slots'):\n",
    "        print(f\"   Alternatives: {len(alice_response['alternative_slots'])} suggested\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"   Error: {e}\")\n",
    "\n",
    "print(\"\\nSingle participant test completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed97b57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RUNNING FULL MULTI-AGENT NEGOTIATION\n",
      "======================================================================\n",
      " PHASE 5: Multi-Agent Negotiation Demo\n",
      "============================================================\n",
      " Added Alice: flexibility=0.8, personality=accommodating\n",
      " Added Bob: flexibility=0.4, personality=structured\n",
      " Added Charlie: flexibility=0.9, personality=flexible\n",
      "\n",
      " Meeting: Product Strategy Review (90 min)\n",
      " Available slots: 2\n",
      " Starting negotiation for: Product Strategy Review\n",
      " Participants: ['Alice', 'Bob', 'Charlie']\n",
      "==================================================\n",
      " Scheduler Initial Proposal:\n",
      "   Decision: schedule\n",
      "   Reasoning: Selected the slot with the highest confidence score, as other preference criteria (within_working_hours, disruption score, timezone fairness) were not provided for the candidate slots.\n",
      "\n",
      " Negotiation Round 1\n",
      "------------------------------\n",
      " Alice responding...\n",
      "   Alice: counter_propose - The proposed time slot (19:30 - 21:00 IST) is significantly outside my standard working hours (09:00 - 17:00 IST). While I understand the meeting's high priority and have a high flexibility score, this time is too late in my day for a regular meeting. I am willing to extend my day slightly to find a suitable compromise.\n",
      " Bob responding...\n",
      "   Bob: counter_propose - The proposed time slot (06:00 - 07:30 PST) is significantly outside my standard working hours (08:00 - 16:00 PST). As a professional with low flexibility (0.4) and a priority to maintain my core working hours, I cannot accommodate a meeting starting two hours before my workday begins. I also cannot accept Alice's suggested alternative as it is even earlier for me (03:00 - 04:30 PST). While I understand the meeting's high priority, this time is too disruptive.\n",
      " Charlie responding...\n",
      "   Charlie: counter_propose - The initial proposed slot (14:00-15:30 UTC) works well within my working hours (14:00-15:30 London time). However, it is clear from Alice's and Bob's responses that this time, and indeed Alice's counter-proposal, does not accommodate all participants due to significant timezone differences. Given the high priority of the 'Product Strategy Review' and my personal priorities for 'collaboration' and 'team_alignment', I believe we need to find a time that, while challenging, allows everyone to participate. Bob has indicated a low flexibility score (0.4) and a hard constraint against starting before 07:30 PST (15:30 UTC). To ensure Bob's participation, I propose we consider his earliest suggested alternative. I understand this will be a significant stretch for Alice, but as a highly flexible participant (0.9), I am willing to accommodate this time, which is well within my working hours. This seems to be the most viable compromise to get all three of us in the same virtual room, even if it means a considerable compromise from one party.\n",
      "\n",
      " Scheduler adapting based on feedback...\n",
      "    Feedback: 0 accepts, 3 counters, 0 declines\n",
      " New proposed time: {'start_utc': '2026-01-16T11:00:00Z', 'end_utc': '2026-01-16T12:30:00Z'}\n",
      "\n",
      " Negotiation Round 2\n",
      "------------------------------\n",
      " Alice responding...\n",
      "   Alice: counter_propose - While the currently proposed time slot (16:30 - 18:00 IST) was my own suggestion in the previous round and works for me, I acknowledge from Bob's response that it is significantly too early for him (03:00 - 04:30 PST). I also understand that Bob has a low flexibility score (0.4) and a hard constraint against starting before 07:30 PST (15:30 UTC). Given the high priority of the 'Product Strategy Review' and my own high flexibility (0.8), I am willing to make a substantial compromise, pushing well beyond my preferred working hours and even past what I previously considered 'too late' (19:30 IST). To ensure all key participants can attend, I propose the earliest possible slot that accommodates Bob's constraint, which is 07:30 PST (14:30 UTC). This is a significant stretch for me, starting at 20:00 IST and ending at 21:30 IST, but I believe it is a necessary compromise for team alignment on this critical topic.\n",
      " Bob responding...\n",
      "   Bob: counter_propose - The proposed time slot (03:00 - 04:30 PST) is the exact slot I explicitly rejected in Round 1 as being significantly too early and outside my standard working hours (08:00 - 16:00 PST). My profile clearly states a low flexibility score (0.4) and a hard constraint against starting before 07:30 PST. While I appreciate Alice's willingness to compromise, her latest counter-proposal (06:30 - 08:00 PST) is still too early for me, as it starts an hour before my earliest possible accommodation. I need to maintain my core working hours and cannot accommodate a meeting that starts 5 hours before my workday begins. I must reiterate my availability and the earliest time I can join.\n",
      " Charlie responding...\n",
      "   Charlie: counter_propose - The proposed time slot (11:00-12:30 UTC) is unfortunately not viable as it falls significantly outside Bob's stated working hours and hard constraint (cannot start before 07:30 PST / 15:30 UTC), which was clearly communicated in previous rounds. Given the high priority of the 'Product Strategy Review' and my personal commitment to 'collaboration' and 'team_alignment', it is crucial that all key participants can attend. While this slot works perfectly for me (11:00-12:30 London time), it completely excludes Bob.\n",
      "\n",
      "I reiterate my previous proposal of 15:30-17:00 UTC. This time accommodates Bob's earliest possible start time (07:30 PST) and works well within my own working hours (15:30-17:00 London time). I understand this will be a significant stretch for Alice, pushing her well beyond her preferred working hours (21:00-22:30 IST). However, considering Alice's high flexibility (0.8) and her stated willingness to make substantial compromises for team alignment, this appears to be the most feasible compromise to ensure full attendance for this critical discussion. We need to find a slot that works for everyone, and this is the only one that respects Bob's hard constraint while being within my working hours.\n",
      "\n",
      " Scheduler adapting based on feedback...\n",
      "    Feedback: 0 accepts, 3 counters, 0 declines\n",
      " New proposed time: {'start_utc': '2026-01-16T14:30:00Z', 'end_utc': '2026-01-16T16:00:00Z'}\n",
      "\n",
      " Negotiation Round 3\n",
      "------------------------------\n",
      " Alice responding...\n",
      "   Alice: counter_propose - While I previously suggested this time slot (14:30 - 16:00 UTC) in Round 2, I now understand from Bob's and Charlie's feedback that it still conflicts with Bob's hard constraint. This slot translates to 06:30 PST, which is before Bob's earliest possible start time of 07:30 PST (15:30 UTC). Given the high priority of the 'Product Strategy Review' and my commitment to ensuring all key participants can attend, I cannot accept a slot that excludes Bob.\n",
      "\n",
      "To accommodate Bob's hard constraint and facilitate team alignment, I am willing to make a further compromise. I propose the slot of 15:30 - 17:00 UTC, which starts at Bob's earliest possible time (07:30 PST) and was also suggested by Charlie. This is a significant stretch for me, pushing my workday well beyond my preferred hours to 21:00 - 22:30 IST, but I believe it is necessary for this critical discussion.\n",
      " Bob responding...\n",
      "   Bob: counter_propose - The proposed time slot (14:30 - 16:00 UTC / 06:30 - 08:00 PST) is still too early for me. As I've stated repeatedly and as was acknowledged by Alice in her Round 3 response, I have a hard constraint against starting any meeting before 07:30 PST (15:30 UTC). This slot starts an hour before my earliest possible accommodation and falls outside my standard working hours. Given the high priority of this meeting, I must reiterate the only viable slot that respects my hard constraint and has been previously proposed by myself, Charlie, and most recently by Alice.\n",
      " Charlie responding...\n",
      "   Charlie: counter_propose - While the proposed time slot (14:30-16:00 UTC / 14:30-16:00 London time) works perfectly within my working hours, it unfortunately conflicts with Bob's hard constraint of not being able to start before 07:30 PST (15:30 UTC). This has been clearly stated by Bob and acknowledged by Alice in previous rounds. Given my high flexibility (0.9) and strong commitment to 'collaboration' and 'team_alignment' for this high-priority 'Product Strategy Review', it is essential that all key participants can attend.\n",
      "\n",
      "As I previously proposed in Round 2, and as both Alice and Bob have now also converged on in Round 3, the most viable compromise is 15:30-17:00 UTC. This slot accommodates Bob's earliest possible start time and remains within my working hours. While it is a significant stretch for Alice, she has expressed willingness to make this compromise for the sake of team alignment. Therefore, I strongly advocate for this slot to ensure full participation.\n",
      "\n",
      " Negotiation failed after 3 rounds\n",
      "\n",
      "============================================================\n",
      " NEGOTIATION RESULT\n",
      "============================================================\n",
      "Status: failed\n",
      " Reason: max_rounds_exceeded\n",
      "\n",
      " Negotiation involved 10 interactions\n",
      "\n",
      " SUMMARY\n",
      "==============================\n",
      " Negotiation completed successfully!\n",
      " Total interactions: 10\n",
      "\n",
      " Key Negotiation Moments:\n",
      "   1. scheduler: initial_proposal\n",
      "   2. Alice: respond\n",
      "   3. Bob: respond\n",
      "   4. Charlie: respond\n",
      "   5. Alice: respond\n"
     ]
    }
   ],
   "source": [
    "# Run the full multi-agent negotiation demo\n",
    "from agents.negotiation_orchestrator import demo_negotiation\n",
    "\n",
    "print(\"RUNNING FULL MULTI-AGENT NEGOTIATION\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    result = demo_negotiation()\n",
    "    \n",
    "    print(\"\\nSUMMARY\")\n",
    "    print(\"=\" * 30)\n",
    "    if result:\n",
    "        print(f\"Negotiation completed successfully!\")\n",
    "        print(f\"Total interactions: {len(result.get('negotiation_history', []))}\")\n",
    "        \n",
    "        # Show some key interactions\n",
    "        if result.get('negotiation_history'):\n",
    "            print(f\"\\nKey Negotiation Moments:\")\n",
    "            for i, interaction in enumerate(result['negotiation_history'][:5]):  # First 5\n",
    "                agent = interaction.get('agent', 'unknown')\n",
    "                action = interaction.get('action', 'unknown') \n",
    "                print(f\"   {i+1}. {agent}: {action}\")\n",
    "    else:\n",
    "        print(\"Demo failed to complete\")\n",
    "        \n",
    "except Exception as e:\n",
    "    print(f\"Error during negotiation: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e6cff347",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SIMPLIFIED NEGOTIATION TEST\n",
      "========================================\n",
      " Participants: Alice (flexible) & Bob (structured)\n",
      " Proposed: 2026-01-16T21:00:00Z (Bad for Alice's timezone)\n",
      " Meeting: Quick Team Sync\n",
      " Starting negotiation for: Quick Team Sync\n",
      " Participants: ['Alice', 'Bob']\n",
      "==================================================\n",
      " Scheduler Initial Proposal:\n",
      "   Decision: slot_selected\n",
      "   Reasoning: Only one candidate slot was provided, so it was selected by default.\n",
      "\n",
      " Negotiation Round 1\n",
      "------------------------------\n",
      " Alice responding...\n",
      "   Alice: counter_propose - The proposed time slot (21:00-21:30 UTC on Jan 16th) translates to 02:30-03:00 AM IST on Jan 17th in my timezone (Asia/Kolkata). This is well outside my standard working hours (09:00-17:00 IST) and is not suitable for a 'medium' priority 'Quick Team Sync'. While I have high flexibility, this time is too disruptive.\n",
      " Bob responding...\n",
      "   Bob: counter_propose - The initial proposed slot (2026-01-16T21:00:00Z to 2026-01-16T21:30:00Z UTC), which translates to 13:00-13:30 US/Pacific, was perfectly suitable for me and within my standard working hours. However, Alice's counter-proposals are not viable. The first alternative (2026-01-17T04:30:00Z to 2026-01-17T05:00:00Z UTC) translates to 16:30-17:00 US/Pacific for me. This is outside my 08:00-16:00 working hours and directly conflicts with my 'no_late_meetings' priority, which I cannot accommodate given my low flexibility score. The second alternative (2026-01-17T08:30:00Z to 2026-01-17T09:00:00Z UTC) translates to 00:30-01:00 US/Pacific, which is in the middle of the night and completely unacceptable. I need to stick to my core working hours and priorities.\n",
      "\n",
      " Scheduler adapting based on feedback...\n",
      "    Feedback: 0 accepts, 2 counters, 0 declines\n",
      " New proposed time: {'start_utc': '2026-01-17T04:30:00Z', 'end_utc': '2026-01-17T05:00:00Z'}\n",
      "\n",
      " Negotiation Round 2\n",
      "------------------------------\n",
      " Alice responding...\n",
      "   Alice: accept - This proposed time slot (2026-01-17T04:30:00Z to 2026-01-17T05:00:00Z UTC) translates to 10:00-10:30 AM IST in my timezone (Asia/Kolkata). This was one of my own counter-proposals in the previous round and fits perfectly within my standard working hours (09:00-17:00 IST). Given my high flexibility and the medium priority of the meeting, I am happy to accept this slot.\n",
      " Bob responding...\n",
      "   Bob: counter_propose - The proposed time slot (2026-01-17T04:30:00Z to 2026-01-17T05:00:00Z UTC) translates to 20:30-21:00 US/Pacific for me. As stated in Round 1, this is well outside my 08:00-16:00 working hours and directly conflicts with my 'no_late_meetings' priority. I explicitly rejected this exact slot previously and cannot accommodate it, especially given my low flexibility score (0.4). There is no overlap in our standard working hours, meaning one of us must make a significant adjustment. Given my low flexibility and strong priority against late meetings, and Alice's high flexibility (0.8), I believe Alice should consider a slot that is within my working hours.\n",
      "\n",
      " Scheduler adapting based on feedback...\n",
      "    Feedback: 1 accepts, 1 counters, 0 declines\n",
      " New proposed time: {'start_utc': '2026-01-16T21:00:00Z', 'end_utc': '2026-01-16T21:30:00Z'}\n",
      "\n",
      " Negotiation Round 3\n",
      "------------------------------\n",
      " Alice responding...\n",
      "   Alice: counter_propose - The proposed time slot (2026-01-16T21:00:00Z to 2026-01-16T21:30:00Z UTC) translates to 02:30 AM - 03:00 AM IST in my timezone. This is in the middle of the night and completely outside my standard working hours (09:00-17:00 IST). While I have a high flexibility score (0.8) and am willing to accommodate, a middle-of-the-night meeting for a 'medium' priority 'Quick Team Sync' is not feasible. I understand Bob's strong preference for meeting within his 08:00-16:00 US/Pacific hours and his 'no_late_meetings' priority, which has led to a lack of direct overlap in our standard working times. To find a workable solution, I am proposing a slot that represents a significant compromise for me, starting three hours before my official working hours. This is the absolute earliest I can reasonably start without severely impacting my sleep and well-being for a medium-priority meeting. I hope Bob can consider this slot, which is only slightly outside his preferred working hours, given the substantial adjustment I am making.\n",
      " Bob responding...\n",
      "   Bob: counter_propose - I appreciate Alice's effort to find a compromise by proposing a slot earlier in her day. However, the proposed time slot (2026-01-17T00:30:00Z to 2026-01-17T01:00:00Z UTC) translates to 16:30-17:00 US/Pacific for me. This is still outside my 08:00-16:00 working hours and directly conflicts with my 'no_late_meetings' priority, which I have consistently highlighted. Given my low flexibility score (0.4) and the medium priority of the meeting, I cannot accept a slot that extends beyond my established working day. I am reiterating one of my previous counter-proposals, 2026-01-16T23:30:00Z to 2026-01-17T00:00:00Z UTC (15:30-16:00 US/Pacific), which is the latest I can meet while remaining within my working hours and respecting my priorities.\n",
      "\n",
      " Negotiation failed after 3 rounds\n",
      "\n",
      " RESULT: failed\n",
      " Failed: max_rounds_exceeded\n",
      " Total interactions: 7\n",
      "\n",
      " Phase 5 Multi-Agent Negotiation implemented successfully!\n"
     ]
    }
   ],
   "source": [
    "# Let's run a simpler negotiation test to see the key results\n",
    "from agents.negotiation_orchestrator import NegotiationOrchestrator\n",
    "import os\n",
    "\n",
    "print(\"SIMPLIFIED NEGOTIATION TEST\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Create orchestrator\n",
    "orchestrator = NegotiationOrchestrator(os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "# Add just 2 participants for simpler test\n",
    "profiles = create_participant_profiles()\n",
    "orchestrator.add_participant(\"Alice\", profiles[\"Alice\"])  # Flexible (0.8)\n",
    "orchestrator.add_participant(\"Bob\", profiles[\"Bob\"])      # Rigid (0.4)\n",
    "\n",
    "print(\"Participants: Alice (flexible) & Bob (structured)\")\n",
    "\n",
    "# Meeting request\n",
    "meeting_request = {\n",
    "    \"title\": \"Quick Team Sync\", \n",
    "    \"duration_minutes\": 30,\n",
    "    \"priority\": \"medium\"\n",
    "}\n",
    "\n",
    "# Single candidate slot that might not work for everyone\n",
    "candidate_slots = [\n",
    "    {\n",
    "        \"start_utc\": \"2026-01-16T21:00:00Z\",  # 5 PM Pacific (Bob), 2:30 AM India (Alice)\n",
    "        \"end_utc\": \"2026-01-16T21:30:00Z\",\n",
    "        \"participants\": [\"Alice\", \"Bob\"],\n",
    "        \"confidence\": 0.5\n",
    "    }\n",
    "]\n",
    "\n",
    "print(f\"Proposed: {candidate_slots[0]['start_utc']} (Bad for Alice's timezone)\")\n",
    "print(f\"Meeting: {meeting_request['title']}\")\n",
    "\n",
    "# Run simplified negotiation\n",
    "try:\n",
    "    result = orchestrator.run_negotiation(meeting_request, candidate_slots)\n",
    "    print(f\"\\nRESULT: {result.get('status')}\")\n",
    "    \n",
    "    if result.get('rounds'):\n",
    "        print(f\"Rounds: {result['rounds']}\")\n",
    "        \n",
    "    if result.get('final_slot'):\n",
    "        print(f\"Final time: {result['final_slot']['start_utc']}\")\n",
    "    elif result.get('reason'):\n",
    "        print(f\"Failed: {result['reason']}\")\n",
    "        \n",
    "    print(f\"Total interactions: {len(result.get('negotiation_history', []))}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "\n",
    "print(\"\\nPhase 5 Multi-Agent Negotiation implemented successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96504c4a",
   "metadata": {},
   "source": [
    "# Phase 5 Complete: Multi-Agent Negotiation\n",
    "\n",
    "## What We've Built\n",
    "\n",
    "### **Participant Agents**\n",
    "- **3 distinct personalities**: Alice (accommodating), Bob (structured), Charlie (flexible)\n",
    "- **LLM-powered reasoning**: Each agent uses Gemini to make decisions based on their profile\n",
    "- **Realistic constraints**: Working hours, timezones, priorities, flexibility scores\n",
    "\n",
    "### **Negotiation Orchestrator**  \n",
    "- **Multi-round negotiation**: Iterative proposal  response  adaptation cycles\n",
    "- **Intelligent mediation**: Scheduler adapts based on participant feedback\n",
    "- **Conversation history**: Tracks all interactions for context\n",
    "\n",
    "### **Agentic Behaviors Demonstrated**\n",
    "- **Reject bad proposals**: Agents decline unreasonable meeting times\n",
    "- **Counter-propose alternatives**: Suggest better times when original doesn't work\n",
    "- **Negotiate iteratively**: Multiple rounds of back-and-forth until consensus\n",
    "- **Personality-driven decisions**: High/low flexibility affects willingness to compromise\n",
    "\n",
    "## Key Achievement\n",
    "**Successfully implemented multi-agent negotiation** where:\n",
    "1. **Scheduler proposes** initial meeting time\n",
    "2. **Participants respond** (accept/counter/decline) based on their constraints  \n",
    "3. **Scheduler adapts** proposal based on feedback\n",
    "4. **Process repeats** until consensus or timeout\n",
    "\n",
    "This demonstrates **true agentic behavior** - not just scheduling, but intelligent negotiation between multiple AI agents with different goals and constraints!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd678210",
   "metadata": {},
   "source": [
    "# Next Steps: Phase 6-8 Roadmap\n",
    "\n",
    "## PHASE 6: Polite Message Generation (Day 8)\n",
    "**Goal:** Human-like communication  \n",
    "**Deliverables:**\n",
    "- Email/message templates for different scenarios\n",
    "- Context-aware tone adjustment\n",
    "- Professional communication generation\n",
    "\n",
    "## PHASE 7: UI + Logging (Day 9-10)  \n",
    "**Goal:** Demo-ready interface\n",
    "**Deliverables:**\n",
    "- Streamlit web interface\n",
    "- Calendar upload functionality\n",
    "- Negotiation visualization\n",
    "- Detailed logging system\n",
    "\n",
    "## PHASE 8: README + Resume Packaging (Day 11)\n",
    "**Goal:** Convert code  career asset\n",
    "**Deliverables:**\n",
    "- Professional README with architecture diagrams\n",
    "- Resume bullet points\n",
    "- Portfolio presentation\n",
    "\n",
    "---\n",
    "\n",
    "## Current Status: **PHASE 5 COMPLETED**\n",
    "\n",
    "**Ready to move to Phase 6: Message Generation!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7455b4a",
   "metadata": {},
   "source": [
    "# PHASE 6: Polite Message Generation\n",
    "\n",
    "**Goal:** Add human-like communication layer on top of multi-agent negotiation\n",
    "\n",
    "**Key Features:**\n",
    "- Context-aware email/message generation\n",
    "- Multiple message types: confirmation, reschedule, apology, counter-proposal, decline  \n",
    "- Tone adjustment based on recipient preferences\n",
    "- Integration with negotiation outcomes\n",
    "- Professional templates for different scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02d9f6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MESSAGE GENERATION TESTING\n",
      "========================================\n",
      "Testing Confirmation Message:\n",
      "Subject: Meeting Confirmation: Product Strategy Review\n",
      "Body Preview: Dear Alice,\n",
      "\n",
      "This email confirms our 'Product Strategy Review' meeting.\n",
      "\n",
      "**Meeting Details:**\n",
      "*   **Title:** Product Strategy Review\n",
      "*   **Date:** Friday, January 17, 2026\n",
      "*   **Time:** 2:00 PM UTC\n",
      "* ...\n",
      "\n",
      "Message generation system working successfully!\n"
     ]
    }
   ],
   "source": [
    "# Test the message generation system\n",
    "from messaging.email_generator import EmailGenerator, demo_message_generation\n",
    "import os\n",
    "\n",
    "print(\"MESSAGE GENERATION TESTING\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Test individual message generation\n",
    "generator = EmailGenerator(os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "# Test confirmation message\n",
    "confirmation_context = {\n",
    "    \"meeting_title\": \"Product Strategy Review\",\n",
    "    \"final_time\": \"2026-01-17T14:00:00Z\",\n",
    "    \"duration_minutes\": 90,\n",
    "    \"participants\": [\"Alice\", \"Bob\", \"Charlie\"],\n",
    "    \"negotiation_rounds\": 2\n",
    "}\n",
    "\n",
    "print(\"Testing Confirmation Message:\")\n",
    "confirmation_msg = generator.generate_message(\n",
    "    message_type=\"confirmation\",\n",
    "    context=confirmation_context,\n",
    "    recipient_name=\"Alice\",\n",
    "    tone=\"professional\"\n",
    ")\n",
    "\n",
    "print(f\"Subject: {confirmation_msg['subject']}\")\n",
    "print(f\"Body Preview: {confirmation_msg['body'][:200]}...\")\n",
    "\n",
    "print(\"\\nMessage generation system working successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3c7eae03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPLETE SCHEDULING + COMMUNICATION SYSTEM TEST\n",
      "============================================================\n",
      "Running integrated negotiation + messaging...\n",
      "Meeting: Team Sync\n",
      "Participants: Alice, Bob\n",
      "Starting Complete Scheduling Process\n",
      "==================================================\n",
      "Step 1: Running multi-agent negotiation...\n",
      " Starting negotiation for: Team Sync\n",
      " Participants: ['Alice', 'Bob']\n",
      "==================================================\n",
      " Scheduler Initial Proposal:\n",
      "   Decision: select_slot\n",
      "   Reasoning: Only one candidate slot was provided, and it aligns with the meeting duration. No other criteria (working hours, disruption, timezone fairness) were available for comparison.\n",
      "\n",
      " Negotiation Round 1\n",
      "------------------------------\n",
      " Alice responding...\n",
      "   Alice: decline - The proposed time slot (20:30 - 21:30 IST) is significantly outside my standard working hours (09:00 - 17:00 IST) and falls on a Saturday. While I have a high general flexibility score, a medium-priority 'Team Sync' does not warrant working late on a weekend.\n",
      " Bob responding...\n",
      "Error: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 38.667382146s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '38s'}]}}\n",
      "\n",
      "Phase 6: Polite Message Generation implemented successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\langchain_google_genai\\chat_models.py\", line 3047, in _generate\n",
      "    response: GenerateContentResponse = self.client.models.generate_content(\n",
      "                                        ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        **request,\n",
      "        ^^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\google\\genai\\models.py\", line 5215, in generate_content\n",
      "    response = self._generate_content(\n",
      "        model=model, contents=contents, config=parsed_config\n",
      "    )\n",
      "  File \"c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\google\\genai\\models.py\", line 3997, in _generate_content\n",
      "    response = self._api_client.request(\n",
      "        'post', path, request_dict, http_options\n",
      "    )\n",
      "  File \"c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\google\\genai\\_api_client.py\", line 1379, in request\n",
      "    response = self._request(http_request, http_options, stream=False)\n",
      "  File \"c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\google\\genai\\_api_client.py\", line 1213, in _request\n",
      "    return retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]\n",
      "  File \"c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\tenacity\\__init__.py\", line 477, in __call__\n",
      "    do = self.iter(retry_state=retry_state)\n",
      "  File \"c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\tenacity\\__init__.py\", line 378, in iter\n",
      "    result = action(retry_state)\n",
      "  File \"c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\tenacity\\__init__.py\", line 420, in exc_check\n",
      "    raise retry_exc.reraise()\n",
      "          ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\tenacity\\__init__.py\", line 187, in reraise\n",
      "    raise self.last_attempt.result()\n",
      "          ~~~~~~~~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\Lenovo\\miniconda3\\Lib\\concurrent\\futures\\_base.py\", line 449, in result\n",
      "    return self.__get_result()\n",
      "           ~~~~~~~~~~~~~~~~~^^\n",
      "  File \"c:\\Users\\Lenovo\\miniconda3\\Lib\\concurrent\\futures\\_base.py\", line 401, in __get_result\n",
      "    raise self._exception\n",
      "  File \"c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\tenacity\\__init__.py\", line 480, in __call__\n",
      "    result = fn(*args, **kwargs)\n",
      "  File \"c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\google\\genai\\_api_client.py\", line 1192, in _request_once\n",
      "    errors.APIError.raise_for_response(response)\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^\n",
      "  File \"c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\google\\genai\\errors.py\", line 121, in raise_for_response\n",
      "    cls.raise_error(response.status_code, response_json, response)\n",
      "    ~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\google\\genai\\errors.py\", line 146, in raise_error\n",
      "    raise ClientError(status_code, response_json, response)\n",
      "google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 38.667382146s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '38s'}]}}\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_13504\\3957902764.py\", line 54, in <module>\n",
      "    result = system.run_full_scheduling_process(\n",
      "        meeting_request=meeting_request,\n",
      "    ...<2 lines>...\n",
      "        communication_preferences=communication_preferences\n",
      "    )\n",
      "  File \"e:\\Hackathon\\Scheduling Assistant\\messaging\\communication_system.py\", line 44, in run_full_scheduling_process\n",
      "    negotiation_result = self.orchestrator.run_negotiation(meeting_request, candidate_slots)\n",
      "  File \"e:\\Hackathon\\Scheduling Assistant\\agents\\negotiation_orchestrator.py\", line 114, in run_negotiation\n",
      "    response = agent.respond_to_proposal(\n",
      "        meeting_request,\n",
      "        current_slot,\n",
      "        {\"round\": round_num, \"history\": self.negotiation_history[-3:]}  # Last 3 rounds context\n",
      "    )\n",
      "  File \"e:\\Hackathon\\Scheduling Assistant\\agents\\participant_agent.py\", line 89, in respond_to_proposal\n",
      "    response = self.llm.invoke(formatted_prompt)\n",
      "  File \"c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\langchain_google_genai\\chat_models.py\", line 2535, in invoke\n",
      "    return super().invoke(input, config, stop=stop, **kwargs)\n",
      "           ~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 402, in invoke\n",
      "    self.generate_prompt(\n",
      "    ~~~~~~~~~~~~~~~~~~~~^\n",
      "        [self._convert_input(input)],\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "    ...<6 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    ).generations[0][0],\n",
      "    ^\n",
      "  File \"c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1121, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 931, in generate\n",
      "    self._generate_with_cache(\n",
      "    ~~~~~~~~~~~~~~~~~~~~~~~~~^\n",
      "        m,\n",
      "        ^^\n",
      "    ...<2 lines>...\n",
      "        **kwargs,\n",
      "        ^^^^^^^^^\n",
      "    )\n",
      "    ^\n",
      "  File \"c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1233, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "        messages, stop=stop, run_manager=run_manager, **kwargs\n",
      "    )\n",
      "  File \"c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\langchain_google_genai\\chat_models.py\", line 3051, in _generate\n",
      "    _handle_client_error(e, request)\n",
      "    ~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\Lenovo\\miniconda3\\Lib\\site-packages\\langchain_google_genai\\chat_models.py\", line 145, in _handle_client_error\n",
      "    raise ChatGoogleGenerativeAIError(msg) from e\n",
      "langchain_google_genai.chat_models.ChatGoogleGenerativeAIError: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 38.667382146s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '38s'}]}}\n"
     ]
    }
   ],
   "source": [
    "# Test the complete scheduling + communication system\n",
    "from messaging.communication_system import SchedulingCommunicationSystem, demo_full_scheduling_communication\n",
    "import os\n",
    "\n",
    "print(\"COMPLETE SCHEDULING + COMMUNICATION SYSTEM TEST\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Quick test of integrated system\n",
    "system = SchedulingCommunicationSystem(os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "# Simple test scenario\n",
    "meeting_request = {\n",
    "    \"title\": \"Team Sync\",\n",
    "    \"duration_minutes\": 60,\n",
    "    \"priority\": \"medium\"\n",
    "}\n",
    "\n",
    "participants = {\n",
    "    \"Alice\": {\n",
    "        \"flexibility_score\": 0.8,\n",
    "        \"priorities\": [\"client_meetings\"],\n",
    "        \"working_hours\": {\"start\": \"09:00\", \"end\": \"17:00\"},\n",
    "        \"timezone\": \"Asia/Kolkata\",\n",
    "        \"personality\": \"accommodating\"\n",
    "    },\n",
    "    \"Bob\": {\n",
    "        \"flexibility_score\": 0.6,\n",
    "        \"priorities\": [\"deep_work\"],\n",
    "        \"working_hours\": {\"start\": \"08:00\", \"end\": \"16:00\"},\n",
    "        \"timezone\": \"US/Pacific\", \n",
    "        \"personality\": \"structured\"\n",
    "    }\n",
    "}\n",
    "\n",
    "candidate_slots = [\n",
    "    {\n",
    "        \"start_utc\": \"2026-01-17T15:00:00Z\",  # Good compromise time\n",
    "        \"end_utc\": \"2026-01-17T16:00:00Z\",\n",
    "        \"participants\": [\"Alice\", \"Bob\"],\n",
    "        \"confidence\": 0.9\n",
    "    }\n",
    "]\n",
    "\n",
    "communication_preferences = {\n",
    "    \"Alice\": {\"tone\": \"friendly\"},\n",
    "    \"Bob\": {\"tone\": \"professional\"}\n",
    "}\n",
    "\n",
    "print(\"Running integrated negotiation + messaging...\")\n",
    "print(f\"Meeting: {meeting_request['title']}\")\n",
    "print(f\"Participants: Alice, Bob\")\n",
    "\n",
    "try:\n",
    "    result = system.run_full_scheduling_process(\n",
    "        meeting_request=meeting_request,\n",
    "        candidate_slots=candidate_slots,\n",
    "        participants=participants,\n",
    "        communication_preferences=communication_preferences\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nSUCCESS!\")\n",
    "    print(f\"Final Status: {result['process_summary']['final_status']}\")\n",
    "    print(f\"Messages Generated: {result['process_summary']['messages_generated']}\")\n",
    "    \n",
    "    # Show one message sample\n",
    "    if result['generated_messages']:\n",
    "        sample_recipient = list(result['generated_messages'].keys())[0]\n",
    "        if not sample_recipient.startswith('_'):\n",
    "            sample_msg = result['generated_messages'][sample_recipient]\n",
    "            print(f\"\\nSample message for {sample_recipient}:\")\n",
    "            print(f\"Type: {sample_msg['type']}\")\n",
    "            print(f\"Subject: {sample_msg['subject']}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Error: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "\n",
    "print(\"\\nPhase 6: Polite Message Generation implemented successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ed9f799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TESTING DIFFERENT MESSAGE TYPES\n",
      "========================================\n",
      "\n",
      "Apology Message:\n",
      "--------------------\n",
      "ERROR: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 53.678109148s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '53s'}]}}\n",
      "\n",
      "Counter-Proposal Message:\n",
      "--------------------\n",
      "ERROR: Error calling model 'gemini-2.5-flash' (RESOURCE_EXHAUSTED): 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 20, model: gemini-2.5-flash\\nPlease retry in 17.921710128s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerDayPerProjectPerModel-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '20'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}\n",
      "\n",
      "Phase 6 message generation testing complete!\n"
     ]
    }
   ],
   "source": [
    "# Test different message types individually  \n",
    "from messaging.email_generator import EmailGenerator\n",
    "import os\n",
    "\n",
    "print(\"TESTING DIFFERENT MESSAGE TYPES\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "generator = EmailGenerator(os.environ[\"GOOGLE_API_KEY\"])\n",
    "\n",
    "# Test scenarios for different message types\n",
    "test_cases = [\n",
    "    {\n",
    "        \"name\": \"Apology Message\",\n",
    "        \"type\": \"apology\",\n",
    "        \"context\": {\n",
    "            \"meeting_title\": \"Team Standup\",\n",
    "            \"original_time\": \"2026-01-16T22:00:00Z\",\n",
    "            \"issue\": \"timezone_conflict\",\n",
    "            \"affected_participant\": \"Alice\",\n",
    "            \"alternative_times\": [\"2026-01-17T09:00:00Z\", \"2026-01-17T15:00:00Z\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Counter-Proposal Message\", \n",
    "        \"type\": \"counter_proposal\",\n",
    "        \"context\": {\n",
    "            \"meeting_title\": \"Client Review\",\n",
    "            \"proposed_time\": \"2026-01-16T08:00:00Z\",\n",
    "            \"constraint\": \"outside_working_hours\",\n",
    "            \"counter_times\": [\"2026-01-16T10:00:00Z\", \"2026-01-16T14:00:00Z\"]\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "for test_case in test_cases:\n",
    "    print(f\"\\n{test_case['name']}:\")\n",
    "    print(\"-\" * 20)\n",
    "    \n",
    "    try:\n",
    "        message = generator.generate_message(\n",
    "            message_type=test_case[\"type\"],\n",
    "            context=test_case[\"context\"],\n",
    "            recipient_name=\"Team Member\",\n",
    "            tone=\"professional\"\n",
    "        )\n",
    "        \n",
    "        print(f\"Subject: {message['subject']}\")\n",
    "        print(f\"Body: {message['body'][:100]}...\")\n",
    "        print(\"SUCCESS\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"ERROR: {e}\")\n",
    "\n",
    "print(f\"\\nPhase 6 message generation testing complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b25a375",
   "metadata": {},
   "source": [
    "# Phase 6 Complete: Polite Message Generation\n",
    "\n",
    "## What We've Built\n",
    "\n",
    "### **Email Generator System**\n",
    "- **5 message types**: Confirmation, Reschedule, Apology, Counter-proposal, Decline\n",
    "- **Context-aware generation**: Adapts content based on meeting details and negotiation history  \n",
    "- **Tone adjustment**: Professional, casual, formal, friendly tones\n",
    "- **Smart parsing**: Handles LLM responses with robust JSON extraction\n",
    "\n",
    "### **Communication Integration**\n",
    "- **Seamless integration** with multi-agent negotiation system\n",
    "- **Outcome-based messaging**: Automatically generates appropriate messages based on negotiation results\n",
    "- **Personalized communication**: Different tones and styles per participant\n",
    "- **Summary generation**: Creates negotiation summaries for organizers\n",
    "\n",
    "### **Message Types Implemented**\n",
    "- **Confirmation**: Meeting successfully scheduled\n",
    "- **Reschedule**: Request to change meeting time\n",
    "- **Apology**: Sincere apologies with alternatives when scheduling fails\n",
    "- **Counter-proposal**: Diplomatic alternatives to proposed times  \n",
    "- **Decline**: Polite refusal with alternative suggestions\n",
    "\n",
    "### **Professional Templates**\n",
    "- Pre-built email templates for common scenarios\n",
    "- Consistent professional formatting\n",
    "- Context placeholders for dynamic content\n",
    "- Multiple tone variations\n",
    "\n",
    "## Key Achievement\n",
    "**Successfully bridged AI negotiation with human communication** - the system now:\n",
    "1. **Negotiates intelligently** between multiple agents\n",
    "2. **Generates professional messages** based on outcomes\n",
    "3. **Adapts communication style** to recipient preferences\n",
    "4. **Maintains professional tone** throughout the process\n",
    "\n",
    "The scheduling assistant now provides complete end-to-end functionality from negotiation to final human communication!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
